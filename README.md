Abstract:-The widespread application of human activity recognition (HAR), which  serves as a bridge to narrow the gaps between healthcare and smart home, is now  moving towards supervising individual health in a manner that will outsmart the  human mind. This paper delves into the depths of HAR and was created to train  machine learning classifiers for HAR based on the increasing number of profes 
sional annotations of activities in free-living settings. Deep learning, which is based  on artificial neural networks, has demonstrated its effectiveness in many areas, such  as virtual assistants, autonomous driving, image recognition and classification, and  speech processing due to its ability to learn from vast quantities of data. In this  study, we present HAR_Net, a two-stage pipeline for solving the problem of HAR  from wearable sensor data. In the first stage, the 3D time-series sensor data is en 
coded into a 2D image using the concept of Gramian Angular Field (GAF). In con trast, in the second stage, the GAF images are classified using a customized Con volutional Neural Network (CNN), which achieves classification accuracies of  90.56%, 92.60%, and 90.4% on the HARTH, HARSense, and Mobile Health Hu man Behaviour Analysis datasets, respectively, outperforming many state-of-the art HAR models.

Provided below are the links of the datasets

1)https://www.kaggle.com/datasets/joebeachcapital/harth-dataset

2)https://ieee-dataport.org/open-access/harsense-statistical-human-activity-recognition-dataset
